**欢迎词与课程介绍**

大家好，各位大模型实战营的小伙伴们：

欢迎来到本节关于普语提示词工程的实践课程。我是今天的讲师，云中江树，同时也是浪GP社区的创始人及结构化提示词的提出者。今天，我们将用大约一小时的时间，为大家深入解析提示词与提示工程的核心概念，并分享撰写高效提示词的七种常见方法及两种实用框架。我们将重点探讨结构化提示词的应用，并通过实践指导大家如何将提示词应用于实际场景中，构建一个利用大模型实现一键生成书籍的创新应用。希望通过本次课程，大家能够全面理解提示词如何调动、激发并释放大模型的强大能力。

**提示词与生成式AI**

那么，究竟什么是提示词呢？其英文为“prompt”，作为调用生成式AI能力的核心接口，提示词在内容生成中扮演着至关重要的角色。从生成内容的角度来看，提示词大致可分为五个方面：文本生成、图像生成、视频生成、音频生成（包括音乐和音效）以及3D人物或物品的生成。以文本生成为例，以ChatGPT、Cloud及Portuguese大模型为代表的大模型提示词，是最关键、最基础且应用最广泛的提示词类型，也是我们今天讨论的重点。

**提示词的应用与模型抽象**

在互联网和社交媒体上，AI生成的图像、视频和音频内容比比皆是，这些均可以通过提示词调用生成式AI的能力来实现。提示词的应用范围广泛，能够充分发挥AI的潜力。今天，我们将专注于大模型的提示词，其他方面则不展开讨论。对于感兴趣的朋友，建议通过互联网查找相关资料进行深入学习。

我们将把文字生成图片及文字生成文字的过程简化为一个模型，包含两个阶段：首先，向AI模型提供输入；随后，模型根据输入生成输出，这一过程即提示词的应用。对于大模型而言，其基本原理在于词源预测。通俗地说，这可以类比为文字接龙游戏，与日常使用的输入法文本预测类似。例如，输入“春眠不觉晓”后，输入法预测“处处闻啼鸟”，选择后继续预测后续内容。尽管这一类比并不完全准确，但它帮助我们更直观地理解大模型的运作机制。在实际应用中，大模型通过获取输入文本，在内部处理中提取文本特征，并据此预测后续文本，输入的文本即是大模型的提示词。以输入法为例，“春眠”为提示词，而“不觉晓”则是模型的预测结果。

**专业术语保留**

在上述内容中，我们将保留以下专业术语的原有形式：InternLM, Lagent, MindSearch, LLamaIndex, OpenCompass, Xtuner, Multi-agent, 书生浦语, InternVL2, transformer。若发现类似术语存在误写，我们将参照上述标准进行修改。

**结语**

希望今天的分享能够帮助大家更好地理解提示词在调用和激发大模型能力方面的重要作用，期待在未来的学习和实践中，与大家共同探索更多可能性。谢谢大家！
以下是对原文本的润色，保持了专业术语的准确性，并使表达更加流畅自然：

---

在第二个图中，提示词为“春眠不觉晓”，模型的输出结果为“处处闻啼鸟”。从提示词的组成部分及其来源来看，大致可以分为三个部分：一是预设提示词，由预训练模型厂商或应用开发者提供；二是用户输入的提示词；三是模型的输出。前两者易于理解，而模型的输出如何理解呢？以本示例为例，“不觉晓”在上一轮中为模型输出，在下一轮中则作为提示词。在多轮对话中，模型的输出同样可作为后续内容的提示词输入。理解这一原理后，我们可知大模型的能力是由提示词引导和激发的。高质量的输入能够引导模型产生高质量的输出，因此提示词对于充分发挥模型能力至关重要。同时，提示词在整个AI应用的开发过程中贯穿始终。

以大模型构建AI应用为例，其通常包含五个部分，形成金字塔结构：首先是基础的模型层，提供底层计算能力及AI能力。如需调用这些能力，需提供提示词。若提示词中包含可变参数或变量，则转化为提示词模板。例如，在翻译任务中，需将待翻译内容输入提示词，此时的翻译提示词即构成提示词模板。通过流程和逻辑将单个提示模板组合成工作流程链，即提示链或AI工作流。通过AI工作流，可更充分地发挥大模型的能力。然而，这一过程中的步骤和流程仍需人工设定与调整。若让模型自行规划流程，则形成智能体，并可为其提供工具，使其访问外部世界，进行网络搜索、文件访问及API调用等。若将这些智能体组合，各自完成独立任务并协同工作以完成更复杂的任务，则构成多智能体系统。

在整个过程中，提示词最接近模型层，起到调用模型能力的基本作用。在后续的链智能体及多智能体系统开发过程中，均需大量使用提示词，即提示工程。提示工程是通过设计和调整输入提示词（即prompts），以改善模型性能或控制输出结果的技术。以下为一个关于提示工程的小实验：向Lagent大模型询问“六”的寓意，如图左侧第一张所示，其更倾向于给出积极的寓意解释。

---

保留了“InternLM”、“Lagent”、“MindSearch”、“LLamaIndex”、“OpenCompass”、“Xtuner”、“Multi-agent”、“书生浦语”、“InternVL2”、“transformer”等专业术语的原有形式。
以下是润色后的文本：

象征着顺利成功与吉祥，在回答中倾向于赋予“六”这一数字以非具体的意义。若观察右边的图示，我们会发现通过改变措辞，将“六寓意什么”调整为“六表示什么”，这一微妙的变化使回答内容更加全面与具体。从1234566点切入，进行了更为详尽与综合的阐述。对于AI大模型而言，我们提供的内容对其回答结果具有显著影响。仅一词之差，即可导致回答效果天壤之别，这正是我们需要精心设计与优化提示词的原因。通过精心设计提示词，我们旨在充分激发并利用AI的能力。

那么，如何有效进行提示工程呢？首先，我们介绍六大原则。第一，提供清晰的指令，包括增加细节性描述，全面系统地阐述需求，如角色扮演、使用分隔符明确输入的不同部分，指定任务步骤。此外，提供示例，明确输出内容的格式与长度等，这是最为关键的一点。若能实现这一点，可解决提示工程中约80%至90%的问题。第二，提供参考内容，包括在知识问答任务中提供背景知识，或在仿写任务中提供示例。第三，将复杂任务拆分为子任务，以克服模型理解能力与上下文长度的限制。在后续应用示例中，我们将写书任务拆分为多个子任务进行。第四，给予AI思考时间，让模型进行链式思考，在回答前给出推理步骤与解决方案。第五，使用外部工具，如调用搜索引擎获取最新内容，或编写代码处理数据。第六，进行系统测试与调整，通过在数据集与各种测试中观察大模型的表现，据此优化提示词。

接下来，我们探讨写好提示词的技巧。首先，描述清晰是关键。如何实现描述清晰？我们提供一个具体实例，推荐大家跟随实例逐步操作，观察大模型如何根据提示词变化调整输出结果。以撰写关于AI大模型训练营的段落为例，最初提示词为“写一段话，介绍AI大模型训练营”。若希望在社交媒体上发布时内容更加生动活泼，可在提示词中加入emoji表情，使描述更为具体与清晰。随后，大模型给出的结果中包含了更多emoji表情。若内容仍显杂乱，可进一步在提示词中加入结构化排版要求，最终大模型给出的结果将包含emoji表情，实现结构化与生动性的完美结合。

请注意，文中保留了InternLM、Lagent、MindSearch、LLamaIndex、OpenCompass、Xtuner、Multi-agent、书生浦语、InternVL2、transformer等专业术语的原有形式，对于任何类似但书写错误的术语均进行了相应修改。
以下是对原文的润色版本，保持了专业术语的准确性，并使表达更加流畅自然：

其排版设计极为出色。此外，通过这一例子，我们可以清晰地看到，我们是如何逐步明确需求、精确添加信息，从而让大模型的输出结果更加准确。在此过程中，需注意一点：对于模型能够理解的内容，如大模型所掌握的概念，我们只需要提供概括性或总结性的描述，使用适当的名词即可。这样，提示词将不会显得冗长。相反，对于模型难以理解的概念，我们则需要提供详细的解释，因为大模型可能未曾接触过这类知识。因此，需要明确告知模型，我们正在讨论什么主题。这一技巧在前面已有提及，其重要性不言而喻，希望大家能够通过这一实例进行实际操作，观察我们是如何逐步提升描述的清晰度，使大模型的结果更为优劣。

第二个技巧是角色扮演。以翻译任务为例，如果我们直接让大模型进行翻译，其初始翻译结果可能如下：“让生命如夏季花朵般美丽，死亡如秋叶般平静。”然而，若在提示词中加入角色扮演的指示，告知模型“作为一名翻译大师，将以下英文句子翻译成中文”，随后提供待翻译的英文句子，其翻译结果将更为精准和优雅：“让生命如夏花般绚烂，死亡如秋叶般静美。”在许多互联网平台，包括GitHub等开源社区中，我们常看到提示词以“想象你是一个某某某”或“你作为一个某某某”等形式出现，这实际上就是运用了角色扮演的技巧。通过赋予模型专家角色，AI生成内容的质量显著提升。当然，这一技巧在不同模型上的表现可能有所差异，有的模型可能效果不明显。在实际应用中，我们应批判性地使用这一技巧。

第三个技巧是提供示例。这也是一个非常实用且常用的技巧，特别是在需要进行仿写、复刻及类似任务时，提供示例往往能让AI表现更佳。以撰写口号为例，“致敬来时路，进化再出发”这一标语广为人知，常用于公司年会、学校活动及组织过程中，因其简洁有力、深入人心而备受青睐。然而，撰写高质量的标语并非易事，往往需要头脑风暴和字斟句酌。此时，可借助AI提供候选方案，作为思考的辅助。具体操作方法如下：向AI提供一段提示词，要求其仿写句子，保持字数和语义连贯性，并给出三个候选句。从图中可以看出，AI仿写的句子结构不太准确，内容质量也有待提高。如何优化结果呢？此时即可运用本章介绍的方法——提供示例。在原有提示词基础上，我们提供了两个示例：“澎湃制示器，同造理想国；泛舟古渡口，倾听时光篇。”提供示例后，模型输出的结果结构更加正确。

请注意，文中保留了InternLM、Lagent、MindSearch、LLamaIndex、OpenCompass、Xtuner、Multi-agent、书生浦语、InternVL2、transformer等专业术语的原有形式。如果存在类似术语但书写错误的情况，请修改为上述术语。
以下是润色后的文本：

内容质量有了显著提升，在实际应用过程中，我们的视力需求并不高，两到三个即可满足要求。我们可以根据实际情况调整这些示例，并注重质量而非数量。第四个技巧是复杂任务的分解，也称为思维链缩写，即著名的COT（Chain of Thought）。其核心原理是让大模型逐步思考，要求其提供推理步骤、推理原因或依据。这类似于我们小时候解数学题的过程：直接心算得出的结果可能准确率较低，但如果我们在草稿纸上一步步计算，写下每一步，最终正确率会有显著提升。对于大模型而言，这一原理同样适用。我们提供了相关示例，使用思维链也非常简单：在指令后加上“请逐步思考”或“请给出推理过程和依据”等描述即可。这种方法本质上将复杂任务拆分为简单任务，模型可自动完成，我们也可手动拆分工作流，指导模型分步执行。

第五个技巧是使用格式符区分语义，这类似于日常写作中使用标点符号。对于模型而言，尤其在区分提示词中的指令性和材料性内容时，这一点尤为重要。例如，在翻译任务中，前面是指令性内容“将下面的中文翻译为英文”，后面则是材料性内容。如果直接将提示词组合给AI，它可能会将材料性内容也视为指令执行，导致翻译任务异常。我们期望完成的是中文到英文的翻译，但最终“提示工程”这一概念被翻译成了日语，因为它被当作指令执行了。为解决这一问题，我们采用格式符区分内容：首先使用引号区分，如第二张图中所示，尽管提示工程仍未被准确翻译为英文。这是由于大模型在理解方面存在缺陷，因此有时需要加强格式区分。我们可以使用自定义符号，如对翻译内容使用井号进行标记。在第三张图中，当翻译内容被井号包裹时，模型能够正确翻译为全部英文。

在实际使用这些格式与大模型对话的过程中，如果对格式符和语法规范不熟悉，我们推荐使用Markdown格式。对于程序员而言，这种格式较为熟悉，且几乎所有大模型对此格式支持良好，上手简单，只需花十几到二十分钟了解核心语法即可。无需成为精通专家，只需掌握基本语法即可。可上网搜索Markdown语法。

注意：保留 InternLM, Lagent, MindSearch, LLamaIndex, OpenCompass, Xtuner, Multi-agent, 书生浦语, InternVL2, transformer 等专业术语的原有形式。如果有类似术语但书写错误，请修改为上述术语。
以下是润色后的文本，保持了专业术语的准确性，使表达更加流畅自然：

在进行简单的学习后，第六个技巧是情感与物质激励。例如，我们可以为被测试者设定一个任务，如前面提到的仿写句子任务。正如前面所介绍的，仿写句子任务能够有效评估模型的能力。然而，如果我们直接要求被测试者完成这项任务，其效果可能并不理想。如果在提示词中融入情感与物质激励，模型的表现则可能有所提升。

如何应用情感与物质激励呢？分为两个方面。首先是情感激励，通过强调任务的重要性，激发被测试者的积极性。例如，告知任务对项目成功至关重要，或对个人职业发展具有重要影响，以此提升其士气。其次是物质激励，虽然实际中并不提供物质奖励，但在提示词中明确表示将给予奖励，如“你将获得200元小费”，这能有效激励被测试者更加积极地完成任务。

总的来说，情感与物质激励不仅适用于人类，对AI模型同样有效。具体原理可参考以下论文。

最后，一个重要的技巧是使用专业术语。例如，在提问时，可以询问“你知道什么是思维链吗？”这里的思维链是指在训练过程中使用的一种技巧，即“Train of thought”。如果我们直接询问“什么是思维链？”，可能得到的回答不够准确，甚至其英文翻译“saw chains”也显得不够精确。但如果我们使用专业的术语“train of thought”进行提问，回答则更加精准，能够准确指出这是在自然语言处理任务中，帮助模型更好地理解句子含义，提高模型的准确性和可靠性。

以上即为分享给各位的七个通用提示词技巧。在实际应用中，应根据具体情况灵活运用这些技巧，以使模型表现更加符合预期。

上述技巧虽较为零散，但如何将这些技巧有机地结合在一起呢？此时，提示词框架就显得尤为重要。接下来，我们将介绍两个提示词框架。

首先是CRISP框架，由OpenAI官方推荐，其核心在于提示词中需涵盖五个方面的内容：首先明确大模型应扮演的角色及其能力；其次提供任务所需的背景信息与上下文，建议使用“context”而非“insight”；第三是指令或任务目标，明确希望大模型完成的任务；第四是回应的风格或方式，即大模型的个性化部分，确定其回答的风格；最后是尝试或实验，允许大模型提供多个答案，如三到四个，以增加满足需求的可能性。

示例提示词如下，可以是英文或中文，包含上述内容即可：

```
请扮演一名资深工程师，具备丰富的项目管理经验，针对以下问题提供专业见解。背景信息：项目面临关键决策点，需评估技术可行性。指令：分析项目的技术挑战，并提出解决方案。回应风格：专业、客观。尝试或实验：请提供三个不同的技术方案。
```

另一个框架是COSA框架，由新加坡科技局在GBT4提示词大赛中推广，大赛冠军采用的正是这一框架。

请注意，文中保留了InternLM、Lagent、MindSearch、LLamaIndex、OpenCompass、Xtuner、Multi-agent、书生浦语、InternVL2、transformer等专业术语的原始形式。对于类似术语，若存在书写错误，请修改为上述术语。
该框架在基本内容上与前面的框架差异不大，但在全面性和结构化书写方面有所提升。具体而言，COSTAR框架涵盖了以下六大方面：

1. **背景**：提供任务的背景信息，这一点与之前的框架相同。
2. **目标**：定义需要执行的任务，与CRISP框架类似。
3. **风格**：指定期望的写作风格或回答风格，包括情感基调。这一点是COSTAR框架相较于CRISP框架的一大改进。
4. **对象与用户**：明确回答的对象及目标用户，以及大模型回复的格式。这是COSTAR框架相较于CRISP框架的另一大特色。
5. **角色类提示词**：对于角色类的提示词，COSTAR框架更为友好，尤其是在虚拟陪伴场景中，需要构建大量虚拟角色时，COSTAR框架更为适用。其书写方式与我们的LANGTG方式较为相似，思想上保持一致。使用结构化提示词后，原本需要像写小作文一样撰写的提示词变得更具指向性和清晰度，可以像填空题一样在结构化提示词模板上直接填写需求和提示词。
6. **结构化模板**：将角色法、任务分解、COT格式法及属性词等模块化思路融合，形成结构化模板。尽管该模板与COSTAR框架相似，但LONG GB的提出时间比COSTAR早了半年以上。

总的来说，COSTAR框架在结构化和模块化方面表现突出，能够帮助用户更系统地使用大模型的能力，是值得仔细参考和应用的。例如，若希望大模型创作诗歌，可以构建一个诗人角色，并赋予其特定技能，如擅长现代诗、七言诗或五言诗，同时设定规则，确保内容积极向上且押韵。通过这种方法，可以更清晰、高效地生成符合要求的内容。
以下是经过润色的文本：

接下来，他的工作流程是怎样的呢？首先，用户提供形式和主题的输入。然后，AI根据用户提供的这些内容创作诗歌，诗歌中包含题目和诗句。在开始阶段，我们的AI扮演诗人的角色，严格遵循预先定义的规则，使用默认的中文语言与用户交流。AI首先会友好地欢迎用户，介绍自己，并告知用户如何使用。这一过程形成了一个结构化的提示词体系。如果我们将其抽象化，可以看到它是一个双层结构：首先由各个模块构成，每个模块下又包含内部的元素。这里不再详细展开，感兴趣的读者可以查阅相关论文。

在不同的应用场景中，AI有不同的基础模块，这些模块已列在左侧的表格中。针对写作、角色扮演、娱乐、学习以及绘画等场景，AI均可以采用不同的模块，并根据实际需求扩展这些模块。在模块内部，元素主要分为赋值型和执行型两类。例如，“profile”和“girl”是赋值型元素，而“workflow”则是执行型元素，指导AI完成特定步骤。具体的内容可以参考我们的开源项目，以及广泛应用在国内的“long gbt结构化提示词”。该提示词范式由字节跳动agents平台和KIMI官方平台共同开发，适用于专家助手等场景。

通过学习“long gbt结构化提示词”，我们可以构建AI应用，充分利用其能力。以下是一些应用案例：

1. **娱乐文案助手**：如“疯狂星期四”的文案助手。通过左侧的提示词，AI能够创作出充满幽默感的文案。例如，当输入“42号混凝土”时，AI便开始以“疯狂星期四”的风格进行创作。最终，无论工作多么辛苦，“疯狂星期四”都能为用户带来快乐与放松，成为他们心中的美好记忆。

2. **社交媒体文案写作**：以小红书平台为例，通过简化提示词，AI能够创作出符合小红书风格的文案。这些提示词已提供在示例文档中，用户可以参考并使用。当将这些提示词输入到模型中时，AI能够生成吸引人的标题和正文，充分展现小红书的风格。

3. **AI在日常生活中的应用**：AI不仅提升了效率，还在许多方面拯救了人们的生活。例如，AI的神奇之处在于它能够通过表情和情绪价值，极大地提升用户体验。

通过这些案例，我们可以看到AI在多个领域的应用潜力，无论是娱乐、社交媒体还是日常生活，AI都能带来显著的提升和便利。
我们可以通过AI技术来辅助我们的工作和学习。例如，我们可以让AI帮助我们编写Excel表格，掌握Office的各种技能，甚至构建出Excel表格的高手。当我们向AI提供特定的提示词时，无论是编写Office宏代码，还是进行其他复杂的操作，AI都能根据我们的需求生成示例代码。我们将这些代码复制到WPS中，即可立即使用。接下来，我们将进入提示词实战环节，大约需要半个小时的时间，完成三个实验。

首先，我们将进行“清晰描述提示词技巧的实战”。接着，我们将展示“结构化提示词生成与应用的实战案例”。最后，我们将探索如何通过“提示链”这一手段，将AI的能力拓展十倍，使其不仅能生成简短文本，还能一键撰写整本书。

现在，让我们逐一展开这些实验。首先，进入书生·浦语大模型的聊天界面，您可以通过以下网址访问：[Internal chat internal](http://www.ai.org.cn)。我们的文档中也提供了链接，或者您可以通过百度搜索“书生·浦语”进入聊天界面。注册并登录后，您将看到一个聊天窗口。接下来，请输入第一个提示词：“写一段话，介绍AI大模型实战营”。点击后发送，书生·浦语将为您生成如下推荐介绍。

如果您希望在介绍中加入表情符号，只需复制提示词并添加表情符号后重新发送给书生·浦语，您将看到包含表情符号的新介绍。若希望内容更加结构化，再次复制提示词并加上“结构化排版”的需求发送，您将获得更清晰的内容。此内容采用Markdown语法，星号和井号等符号为Markdown代码效果。您可以点击“复制”按钮，将内容粘贴到任何Markdown编辑器中查看效果，如使用在线Markdown排版器，粘贴后即可看到右侧所示的清晰美观的效果。

好的，这是我们的第一个实验。接下来，我们将进行“结构化提示词生成与应用的实战”。我们为您准备了相关文档和原始提示词，展示如何使用原始提示词生成优化后的提示词并进行应用。请打开我们刚刚的聊天界面以及书生大模型的文档，翻到“工程实践部分”和“优质应用展示部分”。首先展示的是“自动化生成LGBT提示词”。复制这段提示词，可能与前面PPT中介绍的有细微差异，这是针对书生·浦语模型专门调优的新版提示词“专家助手”。复制此提示词，粘贴到书生·浦语的对话界面，点击“新对话”并粘贴提示词，设置完毕后，AI将回应“你好”。

注意：保留以下专业术语的原有形式：InternLM, Lagent, MindSearch, LLamaIndex, OpenCompass, Xtuner, Multi-agent, 书生·浦语, InternVL2, transformer。如果存在类似术语但书写错误，请修改为上述术语。
我是您的提示词专家助手，随时欢迎您告知我您希望设计的提示词用途。无论是提升文章质量，还是优化编程效率，或是其他任何需求，我们都能为您定制指令。例如，如果您需要一个商务邮件助手提示词，只需将指令发送给我，葡语便会为您撰写并采用Markdown格式提供。接下来，您只需点击右上角的复制按钮，将提示词复制，然后在新对话中粘贴并发送给葡语。您将看到，葡语已通过提示词设置，转化为商务邮件助手，协助您撰写、编辑和优化商务邮件。若需撰写和优化商务邮件，只需将邮件内容发送给葡语，并下达相应指令即可。

我们的第二个实验已成功完成，接下来将演示第三个应用，即通过API、编程或工作流方式，利用提示词大幅拓展AI能力，实现一键生成整本书的应用。需说明的是，此应用为进阶应用，由于时间有限，此处仅展示效果及思路拆解，具体提示词编写及代码创作今日暂不展开。我们的代码、提示词及整个项目均开源，欢迎您学习、拆解、部署并亲自实践，以获得最终效果。

首先，我们来看写书应用的成效。再次打开提示工程文档，翻到第四节“应用开发实战”，体验“使用璞玉大模型一键写书”。以下是我部署的网站服务链接，打开链接后，在输入框中输入主题，如“AI大模型发展历史”，点击“生成书籍”，书籍将在后台生成，耗时约几分钟。在此过程中，可直接尝试让葡语撰写书籍，看看模型如何表现。打开新对话，输入“帮我写一整本书，主题是黑暗大模型发展历史”，葡语将提供整书的章节大纲，但未给出完整内容。再次强调，需完整书写整本书。然而，通过我们开发的提示工程优化手段，能否实现呢？看看我们的“妙笔先生AI智能写书应用”，本书已撰写完成，标题为“AI剧B从诞生到引领未来”，第一章为“理论探索与初期萌芽”。观察进度条，仍需较长时间。

请注意，保留以下专业术语的原有形式：InternLM, Lagent, MindSearch, LLamaIndex, OpenCompass, Xtuner, Multi-agent, 书生浦语, InternVL2, transformer。若有类似术语但书写错误，请修改为上述术语。
第一章至第二章：早期发展与技术突破
在这一部分，我们探讨了人工智能（AI）的早期发展历程，以及推动技术进步的关键突破。专业系统与AI主义的兴起，为后续的技术革新奠定了坚实的基础。

第三章：深度学习的崛起与循环应用
深度学习的出现标志着AI领域的一次重大飞跃。通过循环应用，深度学习模型在处理复杂任务时展现出卓越的性能，为后续的AI技术发展奠定了基础。

第四章：GPT模型的诞生与发展背景与起源
GPT模型是自然语言处理领域的里程碑，其诞生与发展不仅反映了AI技术的进步，也揭示了未来AI发展的方向。

第七章：数据算法的双重革命
数据算法的发展带来了AI领域的又一次革命。通过优化算法与数据处理技术，AI系统的性能得到了显著提升。

第八章至第九章：谷歌的贡献与国际合作
谷歌在AI领域的研究与开发，尤其是其国际合作项目，极大地推动了AI技术的全球化发展。

第十章：政府与政策的引导作用
政府在推动AI技术发展中扮演着重要角色。通过制定相关政策，政府为AI技术的健康发展提供了有力支持。

第十一章至第十二章：未来技术趋势与行业转换
展望未来，AI技术将继续引领行业变革。区块链技术与AI的融合，以及AI大模型对社会的深远影响，预示着智能时代的到来。

关于本书的结构与内容，我们已进行了详尽的介绍。本书共包含20章，全面覆盖了AI技术的各个方面。与传统的聊天对话相比，本书的内容更加丰富，信息量至少增加了十几倍。

接下来，我们将介绍本书的应用构建过程。首先，访问我们的项目源码。该项目在GitHub上开源，地址为https://github.com/lunget-ai/book-AI。如果因网络问题无法访问，您也可以使用国内的getcode平台，地址为https://getcode.com/lgt/book-AI。

在开发机的设置过程中，我们首先访问书生studio网站，网址为https://studio book-ai.org.cn。注册并登录后，创建新的开发机，命名为“prompt”，并选择适合的镜像。本书推荐使用“konda12.2”镜像，点击“使用”后，选择GPU资源。完成设置后，开发机的运行时间约为2小时。

进入开发机后，您将看到全新的code server界面。为方便操作，我们创建了一个新的terminal，以便实时查看命令执行情况。按照文档指引，通过“git clone”命令获取项目代码，项目结构中包含“books”文件夹，其中存放了使用AI生成的书籍。这些书籍不仅包括数百行的文档，还涵盖了AI大模型的图解及数学公式，展示了从入门到精通的完整学习路径。

在整个过程中，我们保留了如“InternLM”、“Lagent”、“MindSearch”、“LLamaIndex”、“OpenCompass”、“Xtuner”、“Multi-agent”、“书生浦语”、“InternVL2”、“transformer”等专业术语的准确形式，确保了文本的专业性与准确性。
以下是润色后的文本：

在项目中，我们使用了三个关键的提示词。第一个用于编写各个章节的内容，第二个用于撰写大纲，而第三个则用于生成标题。关于标题的生成，我们不再进行详细解释。接下来，我们将讨论项目的其他部分。

在项目中，您无需关注特定的文件，这些文件主要是配置文件。其中，book writer.py 是最核心的代码文件。对于熟悉 Python 代码的读者来说，理解和使用这段代码将非常直观。该代码并不复杂，大约包含200行左右，且包含空行、注释和一些无用的代码。此外，readme 文件提供了项目的使用指南，您可以根据该指南进行操作，了解如何运行项目。

首先，您需要在硅基流动上注册免费的 API。具体步骤如下：
1. 打开硅基流动的页面，进入模型广场。
2. 选择免费的普语模型，点击进入“书生葡语”模型页面。
3. 无需修改其他设置，只需在 API 密钥部分点击“新建 API 密钥”。例如，创建“葡语 prompt”密钥。
4. 新建密钥后，复制该密钥。
5. 返回项目目录，下载代码并进行环境配置。按照文档指导进行配置。
6. 在代码页面中粘贴 API 密钥，并运行安装命令。
7. 从硅基流动获取 API key，并配置后续指令。将代码中的 APIK 替换为新的密钥值。

完成环境配置后，使用从硅基流动获取的 API key 配置并执行后续命令。请注意，除了配置 APIK 的值外，其他部分无需修改。

最后，将以下三行 export 代码复制到命令行界面中并粘贴，按照提示进行操作。

请注意保留以下专业术语的原有形式：InternLM, Lagent, MindSearch, LLamaIndex, OpenCompass, Xtuner, Multi-agent, 书生浦语, InternVL2, transformer。如果发现有类似术语但书写错误的情况，请修改为上述正确形式。
以下是润色后的文本，保持了专业术语的准确性，并使表达更加流畅自然：

---

首先，我们进行“粘贴”操作，接着按下“Enter”键以确认设置。这样，环境变量就配置好了。配置完成后，我们将输入最后一个命令，并进行复制、直接粘贴操作。此时，系统可能会报错，提示找不到相关文件或文件夹。这是因为我尚未进入“book AI”项目目录。一旦进入目录后，我们可以再次输入之前的命令：`Python 3book writer`，然后选择“PY”选项，按下“Enter”键启动程序。程序已经开始运行，接下来会提示我们输入书籍的主题，例如“AI是什么”。若继续使用之前的命令，如“AI大模型发展历史”，则再次输入主题后，系统将首先生成书籍的标题，随后创建章节大纲，并撰写正文内容。这个过程可能需要几分钟时间，大家只需耐心等待即可。完成后，系统将保存整本书的20个章节至“books”目录下。通过命令行工具，我们可以轻松打开这本书进行预览。在预览界面中，可以看到章节标题、引言、各小节内容，甚至参考文献等。例如，第二章可能包含逻辑回归的内容，并配有示例图（尽管此处未显示）。在实际应用中，若需使用这些内容，还需对AI生成的内容进行优化。同时，书中还附有准确的数学公式。最后，还有一份结语，共20多章，字数颇丰。

这就是如何运行这个写书项目的过程。若大家对此感兴趣，可深入研究我们的提示词及项目源码。该项目虽小，仅几百行代码，但其核心在于这三个提示词，每个提示词包含几十行内容，总和已超过代码的长度，代码仅起到连接作用。

接下来，我将分享该项目的具体实现方法。在之前的演示中，我们已看到AI无法直接创作整本书，只能生成部分内容。因此，我们可以将生成整本书的任务分解为多个简单任务。例如，若AI无法一次性完成整本书的写作，可以按章节逐一生成。为确保整本书的内容连贯性，我们可以先让AI生成大纲。生成大纲的方法是，先让AI创作书籍的标题和简介。这就是整个项目的构建思路。将项目分解后，我们得到三个子任务：一是创作概要，包括书籍标题和简介；二是创作书籍大纲。

---

希望这段润色后的文本能够满足您的需求。如果您有任何进一步的修改或疑问，请随时告知。
文本润色如下：

该文本不仅包含了每个章节的标题和简介，还详细阐述了书籍创作的正文部分。基于每个章节的标题和简介，我们分别创建了各章节的具体内容。在此过程中，我们需特别注意控制格式和连贯性等方面。同时，大家应知晓单次模型生成内容的效率较低，因此，在操作过程中，我们可并行处理以提高生成速度和质量。

接下来，我们将探讨这三个部分如何通过提示词进行调用和创作。首先，我们来看创作概要。其核心在于提示词的设计。在项目的“title writer”部分，我们仅限30行，赋予其书籍写作专家的角色，以创建吸引人的标题和简介。我们要求标题设计需吸引读者，并避免复杂性。同时，仅需输出标题和简介，避免无关描述。目标设定为根据书籍信息（以变量sim表示），在运行时填充，最终以JSON格式输出结果。我们指定了JSON模板，其中包含需填充的内容，并要求仅输出JSON内容，不包含无关字符。

创作大纲的提示词与前述模板相似，区别在于任务调整，需根据书籍标题和简介设计完整的书籍大纲。我们提供了相关技巧和输出格式要求，期望以Python列表格式输出，长度在10至20行之间，并附上范例供其学习填充。最后，要求仅输出列表内容，不包含无关字符。

完成书籍简介和大纲后，我们根据这些内容创作正文提示词。其结构与前述一致，区别在于任务需根据简介、标题和大纲撰写每章具体内容。我们设定了相应的技巧和规则，并在目标部分先提供书籍简介和本章大纲，要求根据这些内容撰写本章内容。对于输出的格式，我们严格要求使用Markdown排版，详细说明数学公式的写法、章节标题及小标题的格式等，并要求仅输出本章内容，不包含无关字符。

通过约200行的代码，我们将这三个流程串联起来，实现输入主题后一键生成上万字书籍的功能。

以上即为我们今日课程的全部内容。在今日课程中，我们介绍了提示词的概念，以及构建提示词工程的六个准则、七个技巧及两个框架。同时，我们讲解了结构化提示词及其编写方法与规范。最后，我们展示了若干应用实例，并带领大家进行三个由浅入深的小例子实践。

在润色过程中，保留了InternLM、Lagent、MindSearch、LLamaIndex、OpenCompass、Xtuner、Multi-agent、书生浦语、InternVL2、transformer等专业术语的原始形式，确保专业性和准确性。
首先，我们从简单的提示词入手，逐步过渡到生成结构化提示词，并探讨其在实际应用中的使用方法。最后，我们将介绍一个AI工作流，也被称为提示链，通过提示词构建应用，提供更深入、更高级的案例，以展示大模型的强大能力。

总的来说，提示词在调用和激发AI能力方面发挥着至关重要的作用。这一关键点虽然门槛不高，意味着只要有兴趣，任何人都可以轻松参与。因此，希望本课程能够为后续内容的学习奠定坚实的基础。

对于希望进一步了解提示词及其相关技能的朋友，我们推荐访问浪GP的知识库。您可以在网上搜索“long gt”或直接访问LGT点AI，即可获取关于结构化提示词的更详细、更全面的内容，供您进阶学习。同时，我们也强烈建议您多多实践，将AI技术融入到日常生活、工作和学习的各个环节中，只有通过实际操作，才能真正感受到AI的力量，并充分发挥其潜力。

感谢大家的聆听，这是我们今天的课程内容。