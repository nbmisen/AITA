大家好，我是书生实战营第四期的讲师，负责讲解如何玩转书生AI的搜索与多模态产品。目前我们看到的最新web页面，与所有大模型产品一样，书生提供了一个基础对话功能。该产品搭载了英特尔M2.5 20B的开源模型，与我们在Hugging Face或GitHub上下载的版本完全相同。我们可以利用这一功能进行简单的翻译、创作等操作，这里不再赘述。

开发者们可能更关心的是API的稳定性。通过点击页面上的API控制台，我们可以查看关心的快速入门指南，包括API提供的模型种类。目前，API提供了INTEL M2.5 20B 7月19号的版本，与Hugging Face上可下载的版本一致。此模块需要登录后才能访问，所有默认用户每月可获得12000次调用，每分钟可调用10次，每分钟可生成5000个输出token。如需更高的流控配置，建议通过申请项目或完成更多挑战来实现。此外，流控配置主要面向英特尔企业用户，所有每日API调用量可通过调用明细查看。

接下来，我将介绍书生普语。最近，书生普语更新了一个重要模块——智能体。我们可以看到文档助手和MAD Search，作为官方智能体已接入书生普语。MAD Search是最近开源的一个AI搜索引擎，书生普语产品上的MAD Search是Intel小组My Search小组的官方实现，其性能与Perplexity Pro相当。

现在，让我们通过《黑神话：悟空》的例子来看看My Search的工作流程。对于首次使用My Search的小伙伴，我将简要介绍其工作原理。首先，My Search分为主节点和子节点。主节点将用户提出的问题进行拆分，通常会拆分为两到三个子问题，但由于问题简单，这里只拆分了一个。右边的子节点负责搜索并总结搜索结果，然后将这些结论提供给主节点。主节点整合子节点信息，最终给出回复。因此，所有回复都附有引用，且是通过多个子节点整理而成的。对于玩过《黑神话：悟空》的玩家，可以暂停查看，其回复非常准确。在主节点生成时，思维导图不可点击，但生成完成后，可以通过点击思维导图查看子节点生成情况，回复中带有角标，可查看引用来源。

接下来看一个关于诺贝尔奖的例子。主节点将问题拆分为两个子问题，通过子节点在互联网上搜索大量信息并进行整合，最终给出确切回复。对这一领域感兴趣的朋友，可以继续使用MAD Search提问更多有趣的问题，它也可作为科研和学习的有力助手。这里不再逐个查看答案。

另一部分是大家熟悉的长文本阅读功能。通过上传论文或文档，书生普语可帮助梳理文章结构、翻译文档及对论文中的关键贡献进行提问。以MAD Search的这篇论文为例，可以总结其主要贡献并翻译论文内容。

今天的课程就到这里，欢迎大家关注Intel M官网（intelM.ai/zh_CN），获取API开发者社区的更多信息。感谢大家的参与！
以下是经过润色后的文本：

关于英特尔M模型及相关领域内的最新进展，我们提供以下信息：

- 英特尔M模型（Intel M Model）
- Lagent
- MindSearch
- LLamaIndex
- OpenCompass
- Xtuner
- Multi-agent
- 书生浦语（Shusheng Puyu）
- InternVL2
- transformer

请确保在文本中使用上述术语时，保持其准确性和专业性。同时，如遇与上述术语形式相似但存在拼写错误的术语，请参照上述标准进行修正。

润色后的文本不仅保留了专业术语的准确性，还通过清晰的列表形式提高了文本的可读性和专业性。同时，使用“提供以下信息”这样的表述，使信息传递更加正式和专业。