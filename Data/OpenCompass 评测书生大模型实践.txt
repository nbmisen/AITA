各位小伙伴们大家好
今天我们进行书生葡语对实战营课程
思南评测部分的讲解
本次讲解分为两个部分
第一部分是司南评测的整体介绍
第二部分会对司南代码进行实际演练
手把手带大家进行评测代码的实战
接下来我们从第一部分开始
那么首先就有一个问题
我们需要回答
我们为什么需要去做评测这样一件事情
首先评测体系是模型研发的指挥棒
通过评测
我们可以知道哪些大模型性能是突出的
同时评测体系也决定了模型的研发方向
第二呢
在某些垂直领域
比如说医疗金融等这些领域
那它是需要有专业的知识才能够去应用的
这样的模型
我们也是需要去聚焦这些垂直领域
去评测这些领域的模型的能力
第三呢
随着大模型的迅猛发展
大模型安全问题也日益突出
而人工监督费时费力
基于模型的评测
在人类无法提供有效监督时是必由之路
第四发
模型评测是产品落地的守门员
面对具体情景和具体应用
需要基于评测结果开展模型选型和模型准出
好了我们回答了第一个问题
那么接下来在大模型的评测中
他会有面临哪些挑战呢
首先第一个就是全面性
因为大模型它的应用场景是非常非常多的
而且模型的能力现在也是发展的越来越迅速
从最开始的对话到现在的智能体等等
那怎么去构建一个既可以扩展
又可以覆盖面比较广的能力的维持体系呢
就是一个问题
第二个挑战呢就是可能会存在一些数据污染
比如说有的模型
他在你这个评测体系上做了训练
然后他这样刷分出来
这个分数就比较高了
他这个模型它的分数就不可信了
类似于在高考前刷到了高考真题
那么最后他的这高考分数也考出来
并不具有区分度
第三就是评测的成本
因为像现在评测
其实它的成本是非常高的
例如对客观题进行评测
会消耗大量的推理成本
并且需要非常多的GPU资源
而对主观题进行评测
用人工打分
那人工劳务费也成本也是非常高昂了
最后就是鲁棒性问题
有的模型它可能对某些提示的词比较敏感
然后换了一套问法
他可能就做不对了
那么这也是评测需要解决的一个问题
回到我们司南本身
我们是如何去评测大模型呢
那么首先我们会根据模型类型的不同
去给它划分成不同的评测的模型
比方说基座模型和对话模型
那么思南也是支持主流商业模式的API方式的评
测和开源模型加载权重的方式来进行评测
社区用户可以根据需求
采取不同的方法进行评测
然后根据模型问题有没有固定答案
我们又可以将评测分为客观评测和主观评测
进行不同的评测方法
比如说客观评测
那就是一些问答题
选择题之类的
比如说我问某大模型
中国的首都在哪里
然后ABCD分别对应四个选项
其实模型只要去打出A或者B就可以了
或者根据模型的回答提取选项
判断他有没有答对
这种就是客观评测
那么对于主观评测呢
比方说一些开放性的主观问答题
就不像客观评测有一个固定答案
例如我们让大模型写一首诗
然后评段模型A和模型B哪首诗写得更好
那就不是靠一个简单的一些规则
就能够去决定了
所以对于主观评测
我们有人类评测
还有模型评测两种方法
更多的是考虑模型评测
比如我们现在去找市面上比较好的gt模型
gt4模型来给模型A和模型B进行打分
除了客观评测和主观评测
我们还有长文本评测
比如大海捞针
那就是例如在一篇很长的文档里
你可能在某个位置里突然插入了一个
就是毫不相关的一句话
比如我在一本深度学习的书籍里插入了一句嗯
小明在上海人工智能实验室实习
然后把它插入了这本书里面
然后你让大模型读完了这本书之后
再问他小明在哪里实习
如果模型能够回答出来
小明在上海人工智能实验室实习
那么就证明这个模型的成本能力非常好
他能够记住在某个地方读到的这一句话
他是能够理解的
那么司南也是支持这种长文本
大海捞针的检测方法
那我们思南的这个评测体系呢
已经到了2.0阶段了
他是从去年的5月份开始就完成了初步的开发
然后一路迭代
越来越多的科研机构和工作跟司南合作
到了今年的1月30号
正式发布了司南2.0的评测体系越来越完善
也更新了非常多的功能
其中也有非常多社区小伙伴的努力
非常感谢大家一起来努力维护我们的思南
评测体系建设的越来越好
那么思南呢已经广泛用于了各个头部
大模型的研究机构了
而且我们也是获得了matter官方推荐的
唯一一个国产大模型的评测体系
也是目前社区支持的最完善的评测体系
开源评测体系已经有了100多个评测集
50多万道题目
接下来是司南生态的介绍
首先我们是汇集了社区的力量工具
基准榜单三位一体
我们会及时收听社区的一些需求
然后每个月定期更新榜单
实时更新当前哪些模型性能比较好
然后去优化我们的评测工具
最后再给到社区进行反馈
形成一个正反馈循环
我们现在也是有了一个中立
全面的一个性能榜单
已经有了100多个大模型
并且定向加入我们的评测
包括我们还有许多大多模态的榜单
就除了刚刚的这个大语言模型的评测之外
动模态现在也是一直在更新之中的
嗯除了刚刚讲解的比较基础的功能外
我们现在已经有了一个权建工作链
比如评测用的han face的模型
它可能评测的速度比较慢
那么我们是支持去更换推理模型
然后来进行一个推理
后端的提速的
现在我们也在建立一个更加开源开放
共建共享这样一个基准社区
我们容纳了很多数据集
在我们的网页上也可以直接找到
可以点进去看到数据集的详细介绍
包括这个数据集上面各个模型的评测结果
接下来介绍combus bench模型能力洞察
对于闭源评测集呢
在主观评测方面
我们是以对战胜率来进行评测的
包括了创造语言
数学知识推理等题目
对于客观评测模块呢
会以选择题和填空题进行进行考察
包括但不仅限于语言知识推理
数学代码自难题
上面是我们嗯进行评测的时候的一些问题
大家可以暂停看一看
最后呢
compass bench会对其各项能力进行
客观评分和主观评分
最后会以一个非常可视化的一个图表
来进行一个嗯非常直观的一个排名
通过上面的评测的分析
我们可以洞察一些有趣的结论
看模型的整体能力仍然有较大的提升空间
并且我们的闭源大模型能力接近于GBD4水平
国内模型在中文场景具有性能优势
开源社区未来可期复杂的推理
但是仍然是短板
在未来发展趋势分析方面
模型的尺寸会逐渐收敛
大小模型会进行一个并重
稠密模型和moo1之间的之争
仍然需要探索
长文本能力变得日益的重要
基础结构多路线并行
还有复杂推理和智能体应用
仍然需要技术突破
比如现在的模型
在多部复杂推理和各类交互式智能体应用中
仍然还有较大的性能提升空间
最后呢就是基于模型的评价将成为主流
在专业知识领域
普通人类标注人的准确性
可能相比较先进的大模型并无显著优势
并且随着大模型能力的不断增强呢
使用模型对待检测进行啊
性能评估也逐渐成为可能
接下来介绍司南板单矩阵
首先介绍大模型评测体系
司南致力于构建科学领先公平大模型评测体系
携手行业助力通用人工智能发展
我们有着开源评测榜单
闭源评测榜单
社区评测榜单
还有垂类评测榜单
接下来我们会进行一个专门的介绍
首先是compass academic
他已经被学术社区广泛使用
可以反映模型能力的差距
覆盖能力维度全面
还有着基于数据及相关因素的筛选
它可以进行知识理解
对其推理语言方面的一个评测
接着就是我们之前详介绍过的compact bench
在这个基础方面
我们除了之前的语言知识理解之外
还加入了数据代码和推理
更加丰富了他的基础能力
在综合能力上
对于之前的基础能力进行了更多的组合嗯
综合考察了大模型的运用各种知识来进行理解
分析和推理这样的能力
除此之外呢
我们也有着评测基准更新制度
比如评测及每季度进行更新
并且还会吸纳最新
还有比较优秀的一些基准
还有compass arena
就是大模型的竞技场
已经基已经支持了20多个国内外主流模型
同场竞技
欢迎小伙伴们参与投票嗯
来反映真实的用户的反馈
接下来介绍思南评测的研究成果
在论文方面呢
司南已经发布了多篇相关论文
涵盖了大模型评测方面的各个领域
比如m m bench视觉语言模型综合评测基准等
这也是发布了非常多的呃一些成果
然后呢
他也是具具备了非常多的广泛的社区影响力
还比如mass bench多层次数学能力评测基准
Node punch
100万进阶版大模型捞针
cl bench代码解释器能力分析基准
还有boat chat大模型多轮对话评测基准
这些都是司乃取得的非常丰富的学术成果
欢迎小伙伴们加入我们
下面我们来讨论下一代思南的评测方向
下一代大模型评测的发展方向呢
面向GI的评测体系
设计大模型
动态评测
自动化构建策略
并且建立复杂的智能体评测系统
还会对模型性能进行一个分析和探索
并对能力的来源与泛化性进行分析
最后呢构建可靠的自动化主观评测
欢迎大家扫码了解我们的官网嗯
还有GITHUB的源码仓库
并且加入我们的公众号
一起来交流讨论
好的
今天的PPT部分介绍到此结束
接下来我们进行思南代码实战的演练
如何客观全面地评估大语言模型的性能和能力
是一个重要的课题
模型评测不仅能帮助我们
了解不同模型的优势和局限性
还能为模型的改进和应用提供重要的参考依据
在这个背景下面
我们需要一个专业的系统的评测工具
而open compass正是这样一个强大的开源工具
现在我带着大家一起来实践
使用open compass评测大语言模型
首先我们需要准备一个开发机以及配置好环境
在这个地方我们准备了open pass的开发机
然后在开发机里面打开开发机
执行执行这些命令之后
在终端里面执行这个命令之后
额我们就可以可以可以就是得到
就是得到这么一个被激活的
扩大环境输出的目录
在root open pass下面
以及把这个open pass的项目克隆下来了
OK嗯我们使用开发器有多种方式
一个stupid life
第二个是terminal
第三个vx code
你可以看到他们都是使用同一台开发机
都是同样的结果呃
哪种方便就用哪一种
回到如何评测大语言模型这个话题
首先我们考虑到
代言模型有两种常见的使用方式
第一种是通过API服务来嗯来使用
例如嗯OpenAI的GPT系列模型
他们都是闭源的
然后我们是调用它的API服务来使用它
第二种方式的话是下载模型权重
然后自己部署使用呃
例如meta的呃呃拉玛系列模型
上海人工智能实验室的英特LM模型
对应的open compass作为一个单元模型的评测框架
相应的提供了API模型
评测模式和本地模式评测这两种方式
这两种方式
我们这里会以上海人工智能实验室的英特尔
LM模型为例
介绍如何评测API模型
评测API模型的话
我们首先第一点是要获得API呃
key API密钥和AB
你这API服务地址以及模型的名称
在这个地方的话
我们有多种方式
可既可以通过普与官方的地址来获得
也可以通过第三方平台
柜机流动或者其他平台来获得嗯
葡语官方
我们演示一下怎么通过普语官方获得这个API
key和API服务地址
我们点开点开就可以嗯
看到OK在这个官方的接口文档中
我们可以看到多种调用方式
通通过这个线方调用方式的代码
我们能够发现它的呃
它的API服务地址是这个API key
当然是一般情况下都是不会显示的
显示出来
然后磨成名称是这个
有了这些之后
我们就可以接下来配置我们的模型
配置我们的模型呃
要写一个模型配置文件
Ok
然后我们正在open compass目录
然后把这个文件给建立起来
可以点开这个模型配置文件
就是葡语的API的模型配置文件
把这个代码复制进去
好复制进去
可以看到这个配置文件里面的关键信息
就是要配置这个API服务地址
配置这个API key以及模型的名称
陌生的名称
陌生的名称嗯
在这个地方的话
API p i d key的话是在这个API token里面
这里申请的可以创建
创建之后你随意输入一个姓名
提交之后你要复制你的a API key
然后我们通过环境变量的方式来引入
这就是通过环境变量的方式来引入
现在我们要定义这个环境变量
所以所以要按照这个步骤来
把这个引入环境变量
OK我们执行一下命令
好已经引入了
然后我们再看看
再看看是否嗯环境变量复制是否成功
哎哎晓得
好的我们可以看到这个这个API key已经复制好了
然后我们现在接下来就是要配置数据集
配置数据集的话也是要新建这个文件
先接这个文件
然后点击进去
可以看到他这个这个这个脚本文件是以前的
已有的
但是我们为了评测速度要稍微的修改一下
把这个代码复制进来
我们只取一个样本
这样的话更快速的评测呃
为什么只取一个样本呢
是因为官方的API调用它要需要消耗算力嘛
它会有速度限制
每分钟只能处理十个请求
所以就速度就很慢
然后CMMLU这个数据集的话
它是有67个子数据集
每个数据集都会有嗯
几十条甚至上百条几呃
样本就会评测起来会很慢
所以我们就每个数据集只取一个样本
这样的话就能加快评测速度
好这基本上配置完了
配置完了之后
接下来我们就可以进行运行这个评测代码了
但是在评测之前
我们还有一个小小的问题
一个小小的问题是什么嘞
就是我们发现发现这里有有两个
就是在这项目的根目录下面
它是有这个CONFIG文件的对吧
然后在open compass下面也是有
这个也是有这个CONFIG文件夹
这是为什么嘞
这是因为open co呃
我听官方的说法是
因为open呃
compass准备把这个根目录下的这个configure
逐渐的废弃掉嗯
但是当前的版本的话
我们会先搜索根目录下的文件
然后然后去执行
所以在这个地方我们为了防止它嗯
那个呃调用了错误的数据配置
所以我们要按CTRL加P找到
看看有没有重复的
你可以看到在这个看CONFIX
下面有这个重复的文件
这重复的文件你看在这里
我们我们就把它删除
就就把这个
文件给删除
删除之后就免得后面调用
调用的时候是使用的是这个配置文件
我们要使用这个配置文件
OK使用这个配置文件好
最后一步的话
我们就可以通过这个命令来进行执行了
当然评测过程中如果出现一些包的问题
比如说呃有可能会出现这个
CHINESE这个包的问题
你你需要安装一下才行
需要安装一下这个出现这个包没引入的话
现在按理来说是是可以正常评测了
预计要运行10分钟
要运行10分钟
运行10分钟
我们可以看到这里有一个运行的结果嗯
就是每个子数据集要么是百百%
要么就是0%
这是因为我们只用到了一个样本
这个样子我们就基本上嗯可以等一等
看看他那个评测过程
好的已经开始评测了
嗯预计需要评测10分钟
另外对于一些开源的模型
本地模型的评测
我们呃大家可以看一下这个教程的后面部分
open k pass它设计他的评测设计
他就是不会区分区分API模型跟呃
那种权重的模型
所以说评测方式基本上大同小异
嗯大家后面可以仔细去测试一下
按照这个教程